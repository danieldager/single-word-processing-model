{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from wordfreq import iter_wordlist, word_frequency\n",
    "\n",
    "class FastWordSampler:\n",
    "    def __init__(self, language='en', max_words=50000):\n",
    "        self.words = []\n",
    "        self.language = language\n",
    "        self.cumulative_probs = []\n",
    "        \n",
    "        total_freq = 0\n",
    "        for i, word in enumerate(iter_wordlist(language)):\n",
    "            if i >= max_words:\n",
    "                break\n",
    "            freq = word_frequency(word, language)\n",
    "            total_freq += freq\n",
    "            self.words.append(word)\n",
    "            self.cumulative_probs.append(total_freq)\n",
    "        \n",
    "        self.cumulative_probs = np.array(self.cumulative_probs) / total_freq\n",
    "\n",
    "    def sample(self, n_samples):\n",
    "        random_values = np.random.random(n_samples)\n",
    "        indices = np.searchsorted(self.cumulative_probs, random_values)\n",
    "        return [self.words[i] for i in indices]\n",
    "\n",
    "sampler = FastWordSampler()\n",
    "samples = sampler.sample(500)\n",
    "\n",
    "# Optional: Check frequencies of sampled words\n",
    "# from collections import Counter\n",
    "\n",
    "# word_counts = Counter(samples)\n",
    "# print(\"\\nTop 10 most frequently sampled words:\")\n",
    "# for word, count in word_counts.most_common(10):\n",
    "#     print(f\"{word}: {count} times (true frequency: {word_frequency(word, 'en'):.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 sampled words and their phonemes:\n",
      "single: S IH1 NG G AH0 L\n",
      "it: IH1 T\n",
      "corporations: K AO2 R P ER0 EY1 SH AH0 N Z\n",
      "posted: P OW1 S T IH0 D\n",
      "fifth: F IH1 F TH\n",
      "this: DH IH1 S\n",
      "had: HH AE1 D\n",
      "in: IH0 N\n",
      "quasi: K W AA1 S IY0\n",
      "to: T UW1\n"
     ]
    }
   ],
   "source": [
    "from g2p_en import G2p\n",
    "\n",
    "g2p = G2p()\n",
    "words_and_phonemes = [(word, g2p(word)) for word in samples]\n",
    "\n",
    "print(\"\\nFirst 10 sampled words and their phonemes:\")\n",
    "for word, phonemes in words_and_phonemes[:10]:\n",
    "    print(f\"{word}: {' '.join(phonemes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: valley\n",
      "Shape of one-hot encoded tensor: torch.Size([14, 58])\n",
      "One-hot encoded tensor:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import defaultdict\n",
    "\n",
    "# Create a dictionary to map phonemes to indices\n",
    "phoneme_to_index = defaultdict(lambda: len(phoneme_to_index) + 1)\n",
    "\n",
    "# Function to encode a single word's phonemes\n",
    "def encode_word(phonemes):\n",
    "    return [phoneme_to_index[p] for p in phonemes]\n",
    "\n",
    "# Encode all phonemes from each word in the data\n",
    "encoded_phonemes = [torch.tensor(encode_word(phonemes)) for _, phonemes in words_and_phonemes]\n",
    "\n",
    "# Pad sequences to the same length\n",
    "padded_sequences = pad_sequence(encoded_phonemes, batch_first=True, padding_value=0)\n",
    "\n",
    "# Create one-hot encodings\n",
    "vocab_size = len(phoneme_to_index) + 1\n",
    "one_hot_encoded = torch.nn.functional.one_hot(padded_sequences, num_classes=vocab_size).float()\n",
    "\n",
    "# Create a list of (word, one-hot encoded tensor) pairs\n",
    "encoded_data = [(word, one_hot) for (word, _), one_hot in zip(words_and_phonemes, one_hot_encoded)]\n",
    "\n",
    "# Print the result for the first word\n",
    "print(f\"Word: {encoded_data[100][0]}\")\n",
    "print(f\"Shape of one-hot encoded tensor: {encoded_data[100][1].shape}\")\n",
    "print(f\"One-hot encoded tensor:\\n{encoded_data[100][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Separate words and encodings\n",
    "words, encodings = zip(*encoded_data)\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(torch.stack(list(encodings)))\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 10\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Example of iterating through the DataLoader\n",
    "# for batch in dataloader:\n",
    "#     inputs = batch[0]\n",
    "#     print(f\"Batch shape: {inputs.shape}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def text_to_image_tensor(\n",
    "        words: list=[\"text\"], savepath=None, index=1, mirror=False,\n",
    "        fontname='Arial', W = 64, H = 64, size=10, spacing=0,\n",
    "        xshift=0, yshift=-3, upper=False, invert=False, show=None\n",
    "    ):\n",
    "\n",
    "    tensors = []\n",
    "    \n",
    "    for word in words:\n",
    "        if upper: word = word.upper()\n",
    "        if invert: word = word[::-1]\n",
    "        \n",
    "        img = Image.new(\"L\", (W,H), color=10)\n",
    "        fnt = ImageFont.truetype(fontname+'.ttf', size)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "\n",
    "        # Starting word anchor\n",
    "        w = sum([(fnt.getbbox(l)[2] - fnt.getbbox(l)[0]) for l in word])\n",
    "        h = sum([(fnt.getbbox(l)[3] - fnt.getbbox(l)[1]) for l in word]) / len(word)\n",
    "        w = w + spacing * (len(word) - 1)\n",
    "        h_anchor = (W - w) / 2\n",
    "        v_anchor = (H - h) / 2\n",
    "\n",
    "        x, y = (xshift + h_anchor, yshift + v_anchor)\n",
    "        \n",
    "        for l in word:\n",
    "            draw.text((x,y), l, font=fnt, fill=\"white\")\n",
    "            letter_w = fnt.getbbox(l)[2] - fnt.getbbox(l)[0]\n",
    "            x += letter_w + spacing\n",
    "\n",
    "        if x > (W + spacing + 2) or (xshift + h_anchor) < -1:\n",
    "            raise ValueError(f\"Text width is bigger than image. Failed on size:{size}\")\n",
    "        \n",
    "        if savepath:\n",
    "            img.save(f\"{savepath}/{word}.jpg\")\n",
    "\n",
    "        img_np = np.array(img)\n",
    "        img_tensor = torch.from_numpy(img_np)\n",
    "        tensors.append((word, img_tensor))\n",
    "    \n",
    "    return tensors\n",
    "\n",
    "tensors = text_to_image_tensor(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 sampled words and their image tensors:\n",
      "but: torch.Size([64, 64])\n",
      "neighbors: torch.Size([64, 64])\n",
      "new: torch.Size([64, 64])\n",
      "hats: torch.Size([64, 64])\n",
      "0.0: torch.Size([64, 64])\n",
      "to: torch.Size([64, 64])\n",
      "can: torch.Size([64, 64])\n",
      "the: torch.Size([64, 64])\n",
      "supervising: torch.Size([64, 64])\n",
      "this: torch.Size([64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst 10 sampled words and their image tensors:\")\n",
    "for word, tensor in tensors:\n",
    "    print(f\"{word}: {tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader length: 5\n",
      "Batch shape: torch.Size([10, 9, 43])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from g2p_en import G2p\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from wordfreq import iter_wordlist, word_frequency\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\"\"\" Notes on naming:\n",
    "\n",
    "\"phoneme tensors\" are one-hot tensors of a list of phonemes for a single word\n",
    "\"grapheme tensors\" are 1D image tensors of a 64x64 image of a single word\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Sample words based on frequency \"\"\"\n",
    "\n",
    "class WordSampler:\n",
    "    def __init__(self, word_count, language='en', max_words=100000):\n",
    "        self.words = []\n",
    "        self.word_count = word_count\n",
    "        self.language = language\n",
    "        self.cumulative_probs = []\n",
    "        \n",
    "        total_freq = 0\n",
    "        for i, word in enumerate(iter_wordlist(language)):\n",
    "            if i >= max_words:\n",
    "                break\n",
    "            freq = word_frequency(word, language)\n",
    "            total_freq += freq\n",
    "            self.words.append(word)\n",
    "            self.cumulative_probs.append(total_freq)\n",
    "        \n",
    "        self.cumulative_probs = np.array(self.cumulative_probs) / total_freq\n",
    "\n",
    "    def sample(self):\n",
    "        random_values = np.random.random(self.word_count)\n",
    "        indices = np.searchsorted(self.cumulative_probs, random_values)        \n",
    "        return [self.words[i] for i in indices]\n",
    "\n",
    "\n",
    "\"\"\" Generate phonemes for each word \"\"\"\n",
    "\n",
    "def text_to_phoneme(words: list, g2p: G2p):\n",
    "\n",
    "    # Get list of phonemes for each word\n",
    "    phonemes = [g2p(word) for word in words]\n",
    "\n",
    "    # Create a dictionary to map phonemes to indices\n",
    "    phoneme_to_index = defaultdict(lambda: len(phoneme_to_index) + 1)\n",
    "    encoded_phonemes = [[phoneme_to_index[p] for p in phoneme] for phoneme in phonemes]\n",
    "\n",
    "    # Pad sequences to the same length\n",
    "    encoded_phonemes = [torch.tensor(lst) for lst in encoded_phonemes]\n",
    "    padded_sequences = pad_sequence(encoded_phonemes, batch_first=True, padding_value=0)\n",
    "\n",
    "    # Create one-hot encodings for each phoneme\n",
    "    vocab_size = len(phoneme_to_index) + 1\n",
    "    phoneme_tensors = torch.nn.functional.one_hot(padded_sequences, num_classes=vocab_size).float()\n",
    "\n",
    "    return phoneme_tensors\n",
    "\n",
    "\n",
    "\"\"\" Create grapheme tensors for each word \"\"\"\n",
    "\n",
    "def text_to_grapheme(\n",
    "        words: list=[\"text\"], savepath=None, index=1, mirror=False,\n",
    "        fontname='Arial', W = 64, H = 64, size=10, spacing=0,\n",
    "        xshift=0, yshift=-3, upper=False, invert=False, show=None\n",
    "    ):\n",
    "\n",
    "    tensors = []\n",
    "    \n",
    "    for word in words:\n",
    "        if upper: word = word.upper()\n",
    "        if invert: word = word[::-1]\n",
    "        \n",
    "        img = Image.new(\"L\", (W,H), color=10)\n",
    "        fnt = ImageFont.truetype(fontname+'.ttf', size)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "\n",
    "        # Starting word anchor\n",
    "        w = sum([(fnt.getbbox(l)[2] - fnt.getbbox(l)[0]) for l in word])\n",
    "        h = sum([(fnt.getbbox(l)[3] - fnt.getbbox(l)[1]) for l in word]) / len(word)\n",
    "        w = w + spacing * (len(word) - 1)\n",
    "        h_anchor = (W - w) / 2\n",
    "        v_anchor = (H - h) / 2\n",
    "\n",
    "        x, y = (xshift + h_anchor, yshift + v_anchor)\n",
    "        \n",
    "        # Draw the word letter by letter\n",
    "        for l in word:\n",
    "            draw.text((x,y), l, font=fnt, fill=\"white\")\n",
    "            letter_w = fnt.getbbox(l)[2] - fnt.getbbox(l)[0]\n",
    "            x += letter_w + spacing\n",
    "\n",
    "        if x > (W + spacing + 2) or (xshift + h_anchor) < -1:\n",
    "            raise ValueError(f\"Text width is bigger than image. Failed on size:{size}\")\n",
    "        \n",
    "        if savepath:\n",
    "            img.save(f\"{savepath}/{word}.jpg\")\n",
    "\n",
    "        # Convert images to tensors\n",
    "        img_np = np.array(img)\n",
    "        img_tensor = torch.from_numpy(img_np)\n",
    "        tensors.append(img_tensor)\n",
    "    \n",
    "    return tensors\n",
    "\n",
    "\n",
    "\n",
    "class DataGenerator():\n",
    "    def __init__(self, word_count=500, batch_size=10, savepath=None):\n",
    "        self.word_count = word_count\n",
    "        self.batch_size = batch_size\n",
    "        self.sampler = WordSampler(word_count)\n",
    "        self.words = self.sampler.sample()\n",
    "        self.g2p = G2p()\n",
    "\n",
    "\n",
    "    def text_to_phoneme(words: list, g2p: G2p):\n",
    "\n",
    "        # Get list of phonemes for each word\n",
    "        phonemes = [g2p(word) for word in words]\n",
    "\n",
    "        # Create a dictionary to map phonemes to indices\n",
    "        phoneme_to_index = defaultdict(lambda: len(phoneme_to_index) + 1)\n",
    "        encoded_phonemes = [[phoneme_to_index[p] for p in phoneme] for phoneme in phonemes]\n",
    "\n",
    "        # Pad sequences to the same length\n",
    "        encoded_phonemes = [torch.tensor(lst) for lst in encoded_phonemes]\n",
    "        padded_sequences = pad_sequence(encoded_phonemes, batch_first=True, padding_value=0)\n",
    "\n",
    "        # Create one-hot encodings for each phoneme\n",
    "        vocab_size = len(phoneme_to_index) + 1\n",
    "        phoneme_tensors = torch.nn.functional.one_hot(padded_sequences, num_classes=vocab_size).float()\n",
    "\n",
    "        return phoneme_tensors\n",
    "\n",
    "\n",
    "    def text_to_grapheme(\n",
    "            words: list=[\"text\"], savepath=None, index=1, mirror=False,\n",
    "            fontname='Arial', W = 64, H = 64, size=10, spacing=0,\n",
    "            xshift=0, yshift=-3, upper=False, invert=False, show=None\n",
    "        ):\n",
    "\n",
    "        tensors = []\n",
    "        for word in words:\n",
    "            if upper: word = word.upper()\n",
    "            if invert: word = word[::-1]\n",
    "            \n",
    "            img = Image.new(\"L\", (W,H), color=10)\n",
    "            fnt = ImageFont.truetype(fontname+'.ttf', size)\n",
    "            draw = ImageDraw.Draw(img)\n",
    "\n",
    "            # Starting word anchor\n",
    "            w = sum([(fnt.getbbox(l)[2] - fnt.getbbox(l)[0]) for l in word])\n",
    "            h = sum([(fnt.getbbox(l)[3] - fnt.getbbox(l)[1]) for l in word]) / len(word)\n",
    "            w = w + spacing * (len(word) - 1)\n",
    "            h_anchor = (W - w) / 2\n",
    "            v_anchor = (H - h) / 2\n",
    "\n",
    "            x, y = (xshift + h_anchor, yshift + v_anchor)\n",
    "            \n",
    "            # Draw the word letter by letter\n",
    "            for l in word:\n",
    "                draw.text((x,y), l, font=fnt, fill=\"white\")\n",
    "                letter_w = fnt.getbbox(l)[2] - fnt.getbbox(l)[0]\n",
    "                x += letter_w + spacing\n",
    "\n",
    "            if x > (W + spacing + 2) or (xshift + h_anchor) < -1:\n",
    "                raise ValueError(f\"Text width is bigger than image. Failed on size:{size}\")\n",
    "            \n",
    "            if savepath:\n",
    "                img.save(f\"{savepath}/{word}.jpg\")\n",
    "\n",
    "            # Convert images to tensors\n",
    "            img_np = np.array(img)\n",
    "            img_tensor = torch.from_numpy(img_np)\n",
    "            tensors.append(img_tensor)\n",
    "        \n",
    "        return tensors\n",
    "\n",
    "\n",
    "    def generate_phonemes(self):\n",
    "        phoneme_tensors = text_to_phoneme(self.words, self.g2p)\n",
    "        phoneme_dataset = TensorDataset(phoneme_tensors)\n",
    "        phoneme_dataloader = DataLoader(phoneme_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        # analyse the dataloader\n",
    "        print(f\"Dataloader length: {len(phoneme_dataloader)}\")\n",
    "        for batch in phoneme_dataloader:\n",
    "            print(f\"Batch shape: {batch[0].shape}\")\n",
    "            break\n",
    "\n",
    "        return phoneme_dataloader\n",
    "    \n",
    "\n",
    "    def generate_graphemes(self, savepath=None):\n",
    "        grapheme_tensors = text_to_grapheme(self.words, savepath)\n",
    "        grapheme_dataset = TensorDataset(*grapheme_tensors)\n",
    "        grapheme_dataloader = DataLoader(grapheme_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        print(grapheme_tensors[0].shape)\n",
    "\n",
    "        return grapheme_dataloader\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gen = DataGenerator(word_count=50, batch_size=10)\n",
    "    phoneme_dataloader = gen.generate_phonemes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader length: 5\n",
      "Batch shape: torch.Size([10, 10, 46])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from g2p_en import G2p\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from wordfreq import iter_wordlist, word_frequency\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\"\"\" Notes on naming:\n",
    "\n",
    "\"phoneme tensors\" are one-hot tensors of a list of phonemes for a single word\n",
    "\"grapheme tensors\" are 1D image tensors of a 64x64 image of a single word\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Sample words based on frequency \"\"\"\n",
    "\n",
    "class WordSampler:\n",
    "    def __init__(self, word_count, language='en', max_words=100000):\n",
    "        self.words = []\n",
    "        self.word_count = word_count\n",
    "        self.language = language\n",
    "        self.cumulative_probs = []\n",
    "        \n",
    "        total_freq = 0\n",
    "        for i, word in enumerate(iter_wordlist(language)):\n",
    "            if i >= max_words:\n",
    "                break\n",
    "            freq = word_frequency(word, language)\n",
    "            total_freq += freq\n",
    "            self.words.append(word)\n",
    "            self.cumulative_probs.append(total_freq)\n",
    "        \n",
    "        self.cumulative_probs = np.array(self.cumulative_probs) / total_freq\n",
    "\n",
    "    def sample(self):\n",
    "        random_values = np.random.random(self.word_count)\n",
    "        indices = np.searchsorted(self.cumulative_probs, random_values)        \n",
    "        return [self.words[i] for i in indices]\n",
    "\n",
    "\n",
    "class DataGenerator():\n",
    "    def __init__(self, word_count=500, batch_size=10, savepath=None):\n",
    "        self.word_count = word_count\n",
    "        self.batch_size = batch_size\n",
    "        self.sampler = WordSampler(word_count)\n",
    "        self.words = self.sampler.sample()\n",
    "        self.g2p = G2p()\n",
    "\n",
    "    def text_to_phoneme(words: list, g2p: G2p):\n",
    "\n",
    "        # Get list of phonemes for each word\n",
    "        phonemes = [g2p(word) for word in words]\n",
    "\n",
    "        # Create a dictionary to map phonemes to indices\n",
    "        phoneme_to_index = defaultdict(lambda: len(phoneme_to_index) + 1)\n",
    "        encoded_phonemes = [[phoneme_to_index[p] for p in phoneme] for phoneme in phonemes]\n",
    "\n",
    "        # Pad sequences to the same length\n",
    "        encoded_phonemes = [torch.tensor(lst) for lst in encoded_phonemes]\n",
    "        padded_sequences = pad_sequence(encoded_phonemes, batch_first=True, padding_value=0)\n",
    "\n",
    "        # Create one-hot encodings for each phoneme\n",
    "        vocab_size = len(phoneme_to_index) + 1\n",
    "        phoneme_tensors = torch.nn.functional.one_hot(padded_sequences, num_classes=vocab_size).float()\n",
    "\n",
    "        return phoneme_tensors\n",
    "\n",
    "    def text_to_grapheme(\n",
    "            words: list=[\"text\"], savepath=None, index=1, mirror=False,\n",
    "            fontname='Arial', W = 64, H = 64, size=10, spacing=0,\n",
    "            xshift=0, yshift=-3, upper=False, invert=False, show=None\n",
    "        ):\n",
    "\n",
    "        tensors = []\n",
    "        for word in words:\n",
    "            if upper: word = word.upper()\n",
    "            if invert: word = word[::-1]\n",
    "            \n",
    "            img = Image.new(\"L\", (W,H), color=10)\n",
    "            fnt = ImageFont.truetype(fontname+'.ttf', size)\n",
    "            draw = ImageDraw.Draw(img)\n",
    "\n",
    "            # Starting word anchor\n",
    "            w = sum([(fnt.getbbox(l)[2] - fnt.getbbox(l)[0]) for l in word])\n",
    "            h = sum([(fnt.getbbox(l)[3] - fnt.getbbox(l)[1]) for l in word]) / len(word)\n",
    "            w = w + spacing * (len(word) - 1)\n",
    "            h_anchor = (W - w) / 2\n",
    "            v_anchor = (H - h) / 2\n",
    "\n",
    "            x, y = (xshift + h_anchor, yshift + v_anchor)\n",
    "            \n",
    "            # Draw the word letter by letter\n",
    "            for l in word:\n",
    "                draw.text((x,y), l, font=fnt, fill=\"white\")\n",
    "                letter_w = fnt.getbbox(l)[2] - fnt.getbbox(l)[0]\n",
    "                x += letter_w + spacing\n",
    "\n",
    "            if x > (W + spacing + 2) or (xshift + h_anchor) < -1:\n",
    "                raise ValueError(f\"Text width is bigger than image. Failed on size:{size}\")\n",
    "            \n",
    "            if savepath:\n",
    "                img.save(f\"{savepath}/{word}.jpg\")\n",
    "\n",
    "            # Convert images to tensors\n",
    "            img_np = np.array(img)\n",
    "            img_tensor = torch.from_numpy(img_np)\n",
    "            tensors.append(img_tensor)\n",
    "        \n",
    "        return tensors\n",
    "\n",
    "    def generate_phonemes(self):\n",
    "        phoneme_tensors = text_to_phoneme(self.words, self.g2p)\n",
    "        phoneme_dataset = TensorDataset(phoneme_tensors)\n",
    "        phoneme_dataloader = DataLoader(phoneme_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        # analyse the dataloader\n",
    "        print(f\"Dataloader length: {len(phoneme_dataloader)}\")\n",
    "        for batch in phoneme_dataloader:\n",
    "            print(f\"Batch shape: {batch[0].shape}\")\n",
    "            break\n",
    "\n",
    "        return phoneme_dataloader\n",
    "\n",
    "    def generate_graphemes(self, savepath=None):\n",
    "        grapheme_tensors = text_to_grapheme(self.words, savepath)\n",
    "        grapheme_dataset = TensorDataset(*grapheme_tensors)\n",
    "        grapheme_dataloader = DataLoader(grapheme_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        print(grapheme_tensors[0].shape)\n",
    "\n",
    "        return grapheme_dataloader\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gen = DataGenerator(word_count=50, batch_size=10)\n",
    "    phoneme_dataloader = gen.generate_phonemes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 18, 58])\n"
     ]
    }
   ],
   "source": [
    "phoneme_tensors = gen.generate_phonemes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_phoneme(words: list, g2p: G2p):\n",
    "\n",
    "    # Get list of phonemes for each word\n",
    "    phonemes = [g2p(word) for word in words]\n",
    "\n",
    "    # Create a dictionary to map phonemes to indices\n",
    "    phoneme_to_index = defaultdict(lambda: len(phoneme_to_index) + 1)\n",
    "    encoded_phonemes = [[phoneme_to_index[p] for p in phoneme] for phoneme in phonemes]\n",
    "    print(encoded_phonemes)\n",
    "\n",
    "    # Pad sequences to the same length\n",
    "    encoded_phonemes = [torch.tensor(lst) for lst in encoded_phonemes]\n",
    "    padded_sequences = pad_sequence(encoded_phonemes, batch_first=True, padding_value=0)\n",
    "    print(padded_sequences)\n",
    "\n",
    "    # Create one-hot encodings for each phoneme\n",
    "    vocab_size = len(phoneme_to_index) + 1\n",
    "    phoneme_tensors = torch.nn.functional.one_hot(padded_sequences, num_classes=vocab_size).float()\n",
    "\n",
    "    return phoneme_tensors\n",
    "\n",
    "g2p = G2p()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [5, 6, 3, 7], [8, 9, 10, 11, 12, 13, 8, 2, 11, 14, 8, 11]]\n",
      "tensor([[ 1,  2,  3,  4,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 5,  6,  3,  7,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 8,  9, 10, 11, 12, 13,  8,  2, 11, 14,  8, 11]])\n",
      "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]]])\n",
      "torch.Size([3, 12, 15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_phoneme([\"hello\", \"world\", \"TensorDataset\"], g2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swpm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
